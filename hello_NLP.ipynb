{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hello_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPRJ68RrXVDvAKLHzZkcT5V"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLPq9nT7bXN3",
        "colab_type": "text"
      },
      "source": [
        "## The 20 newsgroups dataset \n",
        "\n",
        "This could be like the MNIST of NLP I guess. \n",
        "\n",
        "This dataset is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. But in my case I'll only use three categories. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ-W8p9AHvk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "categories = ['sci.space', \n",
        "              'soc.religion.christian',\n",
        "              'comp.graphics'\n",
        "              ]\n",
        "              \n",
        "twenty_train = fetch_20newsgroups(subset='train',categories = categories , shuffle=True, random_state=42)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBkLw5jhJWV-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1c73b5ea-62a1-41a0-abcb-eca3675e9d25"
      },
      "source": [
        "twenty_train.keys()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QrMAAaKJRa3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85ecc00f-c4c8-42fb-9af9-1c94d2abe432"
      },
      "source": [
        "twenty_train.target_names"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['comp.graphics', 'sci.space', 'soc.religion.christian']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmKrfbyCoWUS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "12bbe910-1a62-4a93-f65b-9ca6eb672393"
      },
      "source": [
        "len(twenty_train.data)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1776"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB8fOI54cBIq",
        "colab_type": "text"
      },
      "source": [
        "## The first objective would be to assign a vector to each sentence/paragraph. \n",
        "\n",
        "For example, we have 2 sentences in a dataset:\n",
        "\n",
        "```\n",
        "[\n",
        "    [\"Hello, I am a human\",         1],\n",
        "    [\"Farewell, I have to leave\",   0]\n",
        "]\n",
        "```\n",
        "\n",
        "The first thing that we'd have to do is to find the `vocabulary`, which is basically a superset containing all the unique words in the dataset. In our case, the vocabulary would look like:\n",
        "\n",
        "```\n",
        "vocab = [\"Hello\", \"I\", \"am\", \"a\", \"human\", \"Farewell\", \"have\", \"to\", \"leave\" ]\n",
        "```\n",
        "\n",
        "The next step is to express the sentences in our dataset as vectors in a an `n` dimensional space where `n` is the size of the vocabulary. \n",
        "\n",
        "For example, let us express the first sentence in the dataset as a vector:\n",
        "\n",
        "\\begin{array}{|l|l|l|}\n",
        "\\hline\n",
        "vocabulary & Hello, \\thinspace I \\thinspace am \\thinspace a  \\thinspace human & Hello,\\thinspace I\\thinspace have \\thinspace to \\thinspace leave \\\\ \\hline\n",
        "Hello    & 1                     & 1                        \\\\ \\hline\n",
        "I        & 1                     & 1                        \\\\ \\hline\n",
        "am       & 1                     & 0                        \\\\ \\hline\n",
        "a        & 1                     & 0                        \\\\ \\hline\n",
        "human    & 1                     & 0                        \\\\ \\hline\n",
        "farewell & 0                     & 0                        \\\\ \\hline\n",
        "have     & 0                     & 1                        \\\\ \\hline\n",
        "to       & 0                     & 1                        \\\\ \\hline\n",
        "leave    & 0                     & 1                        \\\\ \\hline\n",
        "\\end{array}\n",
        "\n",
        "And in our case we use the ` CountVectorizer`, which builds a dictionary of features and transforms documents to feature vectors which can be \"read\" by a model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8dDVd3TPDHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUQKW-NUoRdw",
        "colab_type": "text"
      },
      "source": [
        "## We'll now express all of the sentences in the dataset in form of vectors in a `len(vocabulary)` dimensional space\n",
        "\n",
        "A shape of `(a,b)` below means there are a total of `a` vectors (i.e sentences) in the dataset with all of them expressed in a \"vocabulary space\" of `b` dimensions.\n",
        "\n",
        "The example below has 1663 sentences each represented as a vector in a \"vocabulary space\" of 27829 dimensions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOThJGKtPEug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9f714341-a529-4340-8b87-a0d42fe0bcf3"
      },
      "source": [
        "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
        "X_train_counts.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1776, 31121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1psRwgpPIsj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f94c8e81-a260-4c00-cfd6-4dd80dac168c"
      },
      "source": [
        "len(count_vect.vocabulary_)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31121"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpITSRq8yzfh",
        "colab_type": "text"
      },
      "source": [
        "## Transforming the count matrix to a normalised tf-idf representation\n",
        "\n",
        "**tf-idf** means **term-frequency** times **inverse document-frequency**\n",
        "\n",
        "The goal of using tf-idf instead of the raw frequencies of occurrence of a token in a given document is to scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically less informative. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALnCQt6lPcJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjobFMd7Ufwo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "46a3103d-90cb-4ecf-c756-cbaf2abbcf5c"
      },
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1776, 31121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT1eNYf_qWJ9",
        "colab_type": "text"
      },
      "source": [
        "## Training the classifier with `MultinomialNB`\n",
        "\n",
        "Try and recall bayes theorem from class 12 first. \n",
        "\n",
        "Naive Bayes classifiers assume that the value of a particular feature is independent of the value of any other feature. \n",
        "\n",
        "For example, a fruit may be considered to be an orange if it is orange, round, and about 10 cm in diameter. \n",
        "\n",
        "A naive Bayes classifier considers each of these features to contribute independently to the probability that this fruit is an orange, regardless of any possible correlations between the color, roundness, and diameter features. Which is kind of equivalent to a super shallow neural network (I might be wrong). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN_zRBuFUj7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMDjtoHMUonE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "c3199529-93fa-443e-fa44-23e92566c0cb"
      },
      "source": [
        "docs_new = [\n",
        "            'what if the moon is flat', \n",
        "            \"By the pope!\",\n",
        "            \"You picked the wrong house fool !\",  \n",
        "            \"All we had to do, was follow the damn train, CJ!\" \n",
        "            ]\n",
        "\n",
        "X_new_counts = count_vect.transform(docs_new)\n",
        "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
        "\n",
        "predicted = clf.predict(X_new_tfidf)\n",
        "\n",
        "for doc, category in zip(docs_new, predicted):\n",
        "    print('%r => %s' % (doc, twenty_train.target_names[category]))\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'what if the moon is flat' => sci.space\n",
            "'By the pope!' => soc.religion.christian\n",
            "'You picked the wrong house fool !' => soc.religion.christian\n",
            "'All we had to do, was follow the damn train, CJ!' => soc.religion.christian\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rc53y_8_2zg",
        "colab_type": "text"
      },
      "source": [
        "The model is definitely **not** the best you'll find, but it works on simple sentences. "
      ]
    }
  ]
}